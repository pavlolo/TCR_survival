---
title: 'T-cell survival: with several time points'
author: "Anastasia Pavlova"
date: '2022-10-24'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)

library(tidyverse)
library(ggplot2)
library(forcats)
library(broom)
library(ggbeeswarm)
library(data.table)
library(reshape2)
library(ggridges)
#!!! How to install brms, first we install 'V8' then the package itself
#Sys.setenv(DOWNLOAD_STATIC_LIBV8 = 1)
#install.packages(c("V8", "rstan", "brms"))
library(brms)
library(rstan)
library(formatR)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())


get_os <- function(){
  sysinf <- Sys.info()
  if (!is.null(sysinf)){
  os <- sysinf['sysname']
  if (os == 'Darwin')
    os <- "osx"
  } else { ## mystery machine
    os <- .Platform$OS.type
    if (grepl("^darwin", R.version$os))
      os <- "osx"
    if (grepl("linux-gnu", R.version$os))
      os <- "linux"
  }
  tolower(os)
}
if (get_os() == "osx") {
  read_gz <- function(x) fread(paste("gzcat", x))
} else {
  read_gz <- function(x) fread(paste("zcat", x))
}

rename <- dplyr::rename
select <- dplyr::select
```


## Load and refine data

Let's test the model on vaccination dataset from Pogorelyy et al., 2018. The dataset consists of T-cell repertoire of six samples (three identical twin pairs) at several time points before and after immunization against yellow fever.

```{r message=FALSE, warning=FALSE, echo=FALSE}
setwd('/home/anpavlova/survival_new/YF')


data.raw <- list.files("data", full.names = T) %>%
  as.list %>%
  lapply(function(x) read_gz(x) %>% mutate(sample.id = x)) %>%
  rbindlist

# here we retain relevant columns and create new ones extracting the sample characteristics from file names.

data.long <-data.raw %>% mutate(time.point = str_split(sample.id, "_", simplify = T)[, 2],
                                replica = str_split(sample.id, "_", simplify = T)[, 3],
                                sample.id = stringr::str_extract(sample.id, pattern = "(?<=data/)(.*?)(?=_)"),
                                best.V.gene = str_split(`All V hits`, "[(]", simplify = T)[, 1]) %>% 
  select(c('sample.id', 'replica', 'time.point', 'Clone count', 'Clonal sequence(s)', 'best.V.gene', 'AA. Seq. CDR3')) %>% 
  rename(clone.count = `Clone count`, nt.seq = `Clonal sequence(s)`, aa.seq = `AA. Seq. CDR3`)

# transform time points into numeric value
data.long <- data.long %>% mutate(time.point = recode(time.point, "pre0" = "-7"))  %>% mutate(time.point = as.numeric(time.point)) 

glimpse(data.long)
```

```{r}
data.yf.meta <- tibble(file.name = list.files("data", full.names = T)) %>%
  mutate(sample.id = str_split(list.files("data"), "_.txt", simplify = T)[, 1]) %>%
  separate(sample.id, c("donor.id", "time.point", "replica"))

data.yf.meta
```

```{r}
data.yf <- data.yf.meta %>%
  group_by_all() %>%
  group_modify(~ read_tsv(.y$file.name))

data.yf$clone.id <- with(data.yf, paste(str_split_fixed(`All V hits`, fixed("("), n = 2)[, 1], `Clonal sequence(s)`, sep = "_"))
data.yf <- data.yf %>%
  rename(clone.count = `Clone count`, aa.seq = `AA. Seq. CDR3`) %>%
  select(c(colnames(data.yf.meta), 'clone.count', 'clone.id', 'aa.seq'))

data.yf
```

```{r}
expand.grid(donor.id = unique(data.yf.meta$donor.id),
            time.point.from = unique(data.yf.meta$time.point),
            time.point.to = unique(data.yf.meta$time.point)) %>%
  as.tibble %>%
  group_by_all() %>%
  group_modify(~ read_tsv(donor.id, time.point.from, time.point.to)) %>%
  
  get_data(donor.id, time.point)


  
```


## Clonotype grouping by size (quantiles)
```{r message=FALSE, warning=FALSE}

# define a vector containing time points
s <- sort(unique(data.long$time.point))

quantiles <- function(i){
data.long %>% 
  pivot_wider(names_from = time.point, values_from = clone.count) %>% 
  mutate(pre.quantile = case_when(
    is.na(!! as.name(s[i])) ~ "Missing",
    (!! as.name(s[i])) == 1 ~ "Singleton",
    (!! as.name(s[i])) == 2 ~ "Doubleton",
    (!! as.name(s[i])) == 3 ~ "Tripleton",
    T ~ "Large"),
    pre.point = s[i]) -> data.wide
return(data.wide)
}

data.wide.list<-lapply(1:length(s), quantiles)

data.wide.df <- do.call("rbind", data.wide.list)
rm(data.wide.list)

data.wide.df %>% filter(pre.quantile != "Missing") %>% group_by(pre.quantile,sample.id) %>% 
     summarise(pre.rep = n()) %>% summarise(mean_pre.rep = mean(pre.rep))

data.wide.df %>%
  filter(pre.quantile != "Missing") %>%
  pivot_longer(as.character(all_of(s)), names_to = "time.point", values_to = "clone.count") %>%
  ggplot(aes(x = pre.quantile, 
             fill = sample.id)) +
  geom_bar(position = "dodge") +
  scale_y_log10() +
  geom_hline(yintercept = 100, linetype = "dotted") +
  geom_hline(yintercept = 1000, linetype = "dashed") +
  theme_classic() +
  facet_wrap(~time.point) +
  theme(legend.position = "bottom")

```

```{r,  fig.width = 20, fig.height=20}
 
alpha.prior <- 1
beta.prior <- 1

j<-(1:length(s))

alphabeta <- function(i){
data.wide.df %>% filter(pre.point == as.character(s[i])) %>%
   select(-as.character(all_of(s[j[j<i]]))) %>% 
   pivot_longer(as.character(all_of(s[(i+1):length(s)])), names_to = "time.point", values_to = "clone.count") %>% 
   rename(pre.rep = as.character(s[i])) %>% 
   filter(pre.quantile != "Missing") %>%
   group_by(sample.id, time.point) %>%
   mutate(total.pre = sum(pre.rep, na.rm = T), 
         clones.pre = length(unique(aa.seq[!is.na(pre.rep)]))-1, 
         total.post = sum(clone.count, na.rm = T),
         clones.post = length(unique(aa.seq[!is.na(clone.count)]))-1) %>% 
   group_by(sample.id, time.point, pre.quantile, pre.point) %>%
   mutate(clones.pre.quant = length(unique(aa.seq[!is.na(pre.rep)]))-1) %>%
   group_by(sample.id, time.point, pre.quantile, total.pre, clones.pre, total.post, clones.post, clones.pre.quant, pre.point) %>%
   summarize(alpha = sum(!is.na(clone.count)) + alpha.prior,
             beta = sum(is.na(clone.count)) + beta.prior) %>%
   ungroup
}

data.alphabeta.list <-lapply(head(j, -1), alphabeta)

data.alphabeta.all <- do.call("rbind", data.alphabeta.list)

data.prob <- data.alphabeta.all %>%
  merge(tibble(p = c(0:1000/1000, 10^(-4000:-1000/1000)))) %>%
  group_by(sample.id, time.point, pre.quantile) %>%
  mutate(Pbeta = dbeta(p, alpha, beta)) %>%
  ungroup

data.prob %>% filter(time.point == 0, pre.point == -7) %>% 
  group_by(sample.id, time.point) %>%
  mutate(height = Pbeta/max(Pbeta)) %>%
  ggplot(aes(x = p, y = sample.id, height = height, 
             fill = factor(pre.quantile, levels = c("Singleton",
                                                      "Doubleton",
                                                      "Tripleton",
                                                      "Large"))
  )) +
  geom_ridgeline(color = NA, alpha = 0.9) + 
  scale_x_log10("Capture probability", limits = c(1e-2, 9e-1)) + ylab("Pbeta") +
  scale_fill_brewer("", palette = "Spectral") +
  facet_grid(factor(pre.point, levels = c('-7', '0', '7', '15'))~factor(time.point, levels = c('0', '7', '15', '45')), scales = "free_y") +
  theme_classic() +
  theme(aspect = 1, legend.position = "bottom")

data.prob %>%
  group_by(sample.id, time.point) %>%
  mutate(height = Pbeta/ max(Pbeta)) %>%
  ggplot(aes(x = p, y = sample.id, height = height, 
             fill = factor(pre.quantile, levels = c("Singleton",
                                                      "Doubleton",
                                                      "Tripleton",
                                                      "Large"))
  )) +
  geom_ridgeline(color = NA, alpha = 0.9) + 
  scale_x_log10("Capture probability", limits = c(1e-2, 9e-1)) + ylab("Pbeta") +
  scale_fill_brewer("", palette = "Spectral") +
  #facet_grid(factor(pre.point, levels = c('-7', '0', '7', '15'))~factor(time.point, levels = c('0', '7', '15', '45')), scales = "free_y") +
  theme_classic() +
  theme(aspect = 1, legend.position = "bottom")
```

```{r, fig.width=10, fig.height=10}
# New facet label names for time.point
tp.labs <- c("day 0", "day 7", "day 15", "day 45")
names(tp.labs) <- c("0", "7", "15", "45")

# New facet label names for pre.point
pp.labs <- c("day -7", "day 0", "day 7", "day 15")
names(pp.labs) <- c("-7", "0", "7", "15")



data.alphabeta %>% mutate(time.point = recode(time.point, `0` = "day 0", `7` = "day 7", `15` = "day 15", `45` = "day 45")) %>% 
  ggplot(aes(x = clones.post / clones.pre, y = alpha / (alpha + beta), 
             group = paste(time.point, pre.point, pre.quantile), 
             #linetype = time.point, shape = time.point,
             color = factor(pre.quantile, levels = c("Singleton",
                                                       "Doubleton",
                                                       "Tripleton",
                                                       "Large")))) +
  geom_smooth(method = "lm", aes(), size = 1, se=F) +
  geom_point(size = 5) +
  geom_text(aes(label = sample.id), size = 2, color = "white") +
  scale_x_log10("Clones in subsequent rep. / clones in initial rep.") + 
  scale_y_log10("Capture probability") +
  scale_color_brewer("", palette = "Spectral") +
  facet_grid(pre.point~factor(time.point, levels = c("day 0", "day 7", "day 15", "day 45")), labeller = labeller(pre.point = pp.labs)) +
  theme_classic() +
  theme(aspect = 1, legend.position = "bottom")
```
## Basic linear modelling

Quantifying the effect of various factors -- number of clones detected in donor, number of clones detected in recipient and the frequency quantile of a given clonotype in donor -- on the recapture probability. Log-transformed variables show extremely high correlation.

```{r}
data.coord <- data.alphabeta.df %>%
  group_by(pre.quantile) %>%
  mutate(logRecaptureProb = log(alpha / (alpha + beta)), 
         logClonesSubsequent = log(clones.post),
         logClonesInitial = log(clones.pre)) %>%
  ungroup %>%
  mutate(pre.quantile = factor(pre.quantile, levels = c("Singleton",
                                                       "Doubleton",
                                                       "Tripleton",
                                                       "Large")))
```

Show coefficients of linear model

```{r}
data.coord %>%
  ungroup %>%
  mutate(pre.quantile = as.factor(pre.quantile)) %>%
  do(lm(.$logRecaptureProb ~ .$pre.quantile + .$time.point + .$logClonesSubsequent + .$logClonesInitial) %>% tidy)
```

Show variance explained (ANOVA)

```{r}
data.coord %>%
  ungroup %>%
  mutate(pre.quantile = as.factor(pre.quantile)) %>%
  do(lm(.$logRecaptureProb ~ .$pre.quantile + .$time.point + .$logClonesSubsequent + .$logClonesInitial) %>% aov %>% tidy) %>%
  mutate(var.explained.pct = sumsq / sum(sumsq) * 100) 
```
